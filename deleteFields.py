# -*- coding: utf-8 -*-
"""
Este script realiza a exclus√£o em massa de campos de DMOs (Data Model Objects)
baseado em um arquivo CSV de auditoria.

Vers√£o: 8.0 - Com Logs de Sucesso e Falha em CSV

Metodologia:
- Utiliza o fluxo de autentica√ß√£o JWT Bearer Flow (com certificado).
- Suporta o uso de proxy atrav√©s da vari√°vel de ambiente 'PROXY_URL'.
- L√™ um arquivo CSV delimitado por PONTO E V√çRGULA (';').
- Para cada campo a ser exclu√≠do:
  - Remove o mapeamento associado. Trata erros 404 (j√° removido) e 412 (depend√™ncia)
    de forma inteligente.
  - Tenta deletar o campo usando o ID da coluna 'DELETION_IDENTIFIER'.
  - L√≥gica Robusta de Erro 500: Trata erros 500 com uma verifica√ß√£o posterior.
- Relat√≥rio Final: Ao final da execu√ß√£o, exibe um resumo no console e gera dois
  arquivos CSV:
    1. 'deletions_success_log.csv': Com os campos deletados com sucesso.
    2. 'deletions_failure_log.csv': Com os campos que falharam e o motivo.

!! ATEN√á√ÉO !!
!! ESTE SCRIPT √â DESTRUTIVO E DELETA METADADOS PERMANENTEMENTE. !!
!! USE COM EXTREMO CUIDADO E FA√áA BACKUPS QUANDO APLIC√ÅVEL. !!
"""
import os
import time
import asyncio
import csv
import argparse
from urllib.parse import urlencode

import jwt
import requests
import aiohttp
from dotenv import load_dotenv

# --- Configura√ß√£o de Autentica√ß√£o e Proxy ---

def get_access_token():
    """Autentica com o Salesforce usando o fluxo JWT Bearer Flow."""
    print("üîë Autenticando com o Salesforce via JWT (certificado)...")
    load_dotenv()
    
    sf_client_id = os.getenv("SF_CLIENT_ID")
    sf_username = os.getenv("SF_USERNAME")
    sf_audience = os.getenv("SF_AUDIENCE")
    sf_login_url = os.getenv("SF_LOGIN_URL")

    proxy_url = os.getenv("PROXY_URL")
    proxies = {"http": proxy_url, "https": proxy_url} if proxy_url else None
    
    if proxies:
        print(f"üåç Usando proxy para autentica√ß√£o: {proxy_url}")

    if not all([sf_client_id, sf_username, sf_audience, sf_login_url]):
        raise ValueError("Uma ou mais vari√°veis de ambiente para o fluxo JWT est√£o faltando.")
    
    try:
        with open('private.pem', 'r') as f: 
            private_key = f.read()
    except FileNotFoundError:
        print("‚ùå Erro: Arquivo 'private.pem' n√£o encontrado."); raise
        
    payload = {'iss': sf_client_id, 'sub': sf_username, 'aud': sf_audience, 'exp': int(time.time()) + 300}
    assertion = jwt.encode(payload, private_key, algorithm='RS256')
    params = {'grant_type': 'urn:ietf:params:oauth:grant-type:jwt-bearer', 'assertion': assertion}
    token_url = f"{sf_login_url}/services/oauth2/token"
    
    try:
        res = requests.post(token_url, data=params, proxies=proxies)
        res.raise_for_status()
        print("‚úÖ Autentica√ß√£o bem-sucedida.")
        return res.json()
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erro na autentica√ß√£o com Salesforce: {e.response.text if e.response else e}"); raise


# --- Fun√ß√µes da API ---

async def delete_field_mapping(session, instance_url, obj_mapping_id, field_mapping_id, field_name_for_log, dry_run=False):
    """Deleta o mapeamento de um campo, tratando erros 404 e 412 de forma inteligente."""
    delete_url = (f"{instance_url}/services/data/v64.0/ssot/data-model-object-mappings/"
                  f"{obj_mapping_id}/field-mappings/{field_mapping_id}")

    if dry_run:
        print(f"üê´ [SIMULA√á√ÉO] Removeria o mapeamento do campo: {field_name_for_log}")
        return True, "Modo de Simula√ß√£o (Dry Run)"
    
    try:
        async with session.delete(delete_url) as response:
            if response.status in [204, 404]:
                if response.status == 204:
                    print(f"‚úÖ Mapeamento do campo '{field_name_for_log}' removido com sucesso.")
                return True, "Mapeamento removido ou j√° inexistente"
            
            elif response.status == 412:
                print(f"‚ö†Ô∏è  Depend√™ncia encontrada para {field_name_for_log}. A exclus√£o do mapeamento foi bloqueada pela plataforma.")
                reason = "Falha de pr√©-condi√ß√£o (412): O campo √© referenciado em outra funcionalidade (ex: Calculated Insight). A depend√™ncia deve ser removida manualmente na plataforma."
                return False, reason
            
            else:
                error_text = await response.text()
                print(f"‚ùå Falha ao remover mapeamento de {field_name_for_log}: {response.status} - {error_text}")
                return False, f"Erro ao remover mapeamento {response.status}: {error_text}"
    except aiohttp.ClientError as e:
        print(f"‚ùå Erro de conex√£o ao remover mapeamento de {field_name_for_log}: {e}")
        return False, f"Erro de conex√£o: {e}"

async def verify_field_deletion(session, instance_url, field_id):
    """Verifica se um campo ainda existe consultando seu ID via Tooling API."""
    soql_query = f"SELECT Id FROM MktDataModelField WHERE Id = '{field_id}'"
    params = {'q': soql_query}
    url = f"{instance_url}/services/data/v64.0/tooling/query?{urlencode(params)}"
    try:
        async with session.get(url) as response:
            response.raise_for_status()
            data = await response.json()
            return not data.get('records')
    except aiohttp.ClientError as e:
        print(f"‚ùå Erro durante a verifica√ß√£o da exclus√£o: {e}")
        return False

async def delete_dmo_field(session, instance_url, field_id, field_name_for_log, dry_run=False):
    """Deleta um √∫nico campo de DMO, com l√≥gica de verifica√ß√£o para erro 500."""
    delete_url = f"{instance_url}/services/data/v64.0/tooling/sobjects/MktDataModelField/{field_id}"
    
    if dry_run:
        print(f"üê´ [SIMULA√á√ÉO] Deletaria o campo: {field_name_for_log} (ID: {field_id})")
        return True, "Modo de Simula√ß√£o (Dry Run)"

    try:
        async with session.delete(delete_url) as response:
            error_text = await response.text()

            if response.status == 204:
                print(f"‚úÖ Campo deletado com sucesso: {field_name_for_log}")
                return True, "Deletado com Sucesso"
            
            elif response.status == 500:
                print(f"‚ö†Ô∏è  Recebido erro 500 para o campo '{field_name_for_log}'. Tentando verificar o status da exclus√£o...")
                await asyncio.sleep(3)
                
                is_truly_deleted = await verify_field_deletion(session, instance_url, field_id)
                
                if is_truly_deleted:
                    print(f"‚úÖ Verifica√ß√£o confirmou que o campo '{field_name_for_log}' foi deletado com sucesso.")
                    return True, "Deletado com Sucesso (Ap√≥s verifica√ß√£o do erro 500)"
                else:
                    print(f"‚ùå Verifica√ß√£o mostrou que o campo '{field_name_for_log}' ainda existe. A exclus√£o falhou.")
                    return False, f"Erro 500 e verifica√ß√£o confirmou falha: {error_text}"
            
            else:
                print(f"‚ùå Falha ao deletar o campo {field_name_for_log}: {response.status} - {error_text}")
                return False, f"Erro {response.status}: {error_text}"
                
    except aiohttp.ClientError as e:
        print(f"‚ùå Erro de conex√£o ao deletar o campo {field_name_for_log}: {e}")
        return False, f"Erro de conex√£o: {e}"

# --- L√≥gica de Orquestra√ß√£o e Relat√≥rios ---

def write_success_log_to_csv(success_list, filename="deletions_success_log.csv"):
    """Gera um arquivo CSV com a lista de campos deletados com sucesso."""
    headers = ['DMO_DISPLAY_NAME', 'FIELD_DISPLAY_NAME']
    try:
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile, delimiter=';')
            writer.writerow(headers)
            for item in success_list:
                parts = item.split('.', 1)
                dmo_name, field_name = (parts[0], parts[1]) if len(parts) == 2 else (item, '')
                writer.writerow([dmo_name, field_name])
        print(f"üìù Relat√≥rio de sucessos salvo em '{filename}'")
    except IOError as e:
        print(f"‚ùå Erro ao escrever o arquivo de log de sucessos CSV: {e}")

# NOVA FUN√á√ÉO PARA GERAR O CSV DE FALHAS
def write_failure_log_to_csv(failure_list, filename="deletions_failure_log.csv"):
    """Gera um arquivo CSV com os detalhes das falhas na dele√ß√£o."""
    headers = ['DMO_DISPLAY_NAME', 'FIELD_DISPLAY_NAME', 'REASON']
    try:
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=headers, delimiter=';')
            writer.writeheader()
            for failure in failure_list:
                full_name = failure.get('field', '')
                parts = full_name.split('.', 1)
                dmo_name, field_name = (parts[0], parts[1]) if len(parts) == 2 else (full_name, '')
                
                writer.writerow({
                    'DMO_DISPLAY_NAME': dmo_name,
                    'FIELD_DISPLAY_NAME': field_name,
                    'REASON': failure.get('reason', 'N/A')
                })
        print(f"üìù Relat√≥rio de falhas salvo em '{filename}'")
    except IOError as e:
        print(f"‚ùå Erro ao escrever o arquivo de log de falhas CSV: {e}")

async def process_single_field_deletion(session, instance_url, row_data, dry_run):
    field_log_name = f"{row_data['DMO_DISPLAY_NAME']}.{row_data['FIELD_DISPLAY_NAME']}"
    obj_mapping_id = row_data.get("OBJECT_MAPPING_ID")
    field_mapping_id = row_data.get("FIELD_MAPPING_ID")

    has_mapping = obj_mapping_id and obj_mapping_id != "N√£o possui mapeamento"
    if has_mapping:
        print(f"   - Campo '{field_log_name}' possui mapeamento. Processando remo√ß√£o...")
        map_success, map_reason = await delete_field_mapping(
            session, instance_url, obj_mapping_id, field_mapping_id, field_log_name, dry_run
        )
        if not map_success:
            return field_log_name, False, map_reason
    
    field_id = row_data.get('DELETION_IDENTIFIER')
    if not field_id or len(field_id) < 15:
        msg = f"Coluna 'DELETION_IDENTIFIER' est√° vazia ou cont√©m um ID inv√°lido ('{field_id}')."
        print(f"‚ùå Erro: {msg} ({field_log_name})")
        return field_log_name, False, msg
    
    print(f"   - ID t√©cnico lido do arquivo para {field_log_name}: {field_id}")
    
    delete_success, delete_reason = await delete_dmo_field(
        session, instance_url, field_id, field_log_name, dry_run
    )
    return field_log_name, delete_success, delete_reason


async def mass_delete_fields(file_path, dry_run):
    """Orquestra o processo de leitura, confirma√ß√£o e exclus√£o de campos."""
    
    try:
        with open(file_path, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f, delimiter=';')
            required_cols = ['DELETAR', 'DMO_DISPLAY_NAME', 'FIELD_DISPLAY_NAME', 
                             'OBJECT_MAPPING_ID', 'FIELD_MAPPING_ID', 'DELETION_IDENTIFIER']
            if not all(col in reader.fieldnames for col in required_cols):
                missing = [col for col in required_cols if col not in reader.fieldnames]
                print(f"‚ùå Erro: O arquivo CSV '{file_path}' n√£o cont√©m as colunas necess√°rias: {', '.join(missing)}")
                return
            all_rows = list(reader)
    except FileNotFoundError:
        print(f"‚ùå Erro: O arquivo de auditoria '{file_path}' n√£o foi encontrado.")
        return

    fields_to_delete = [
        row for row in all_rows if row.get('DELETAR', 'NAO').upper() == 'SIM'
    ]

    if not fields_to_delete:
        print("üôÇ Nenhum campo marcado com 'SIM' na coluna 'DELETAR'. Nenhuma a√ß√£o a ser feita.")
        return

    print("="*60)
    print("‚ö†Ô∏è ATEN√á√ÉO: Os seguintes campos est√£o marcados para DELE√á√ÉO PERMANENTE:")
    print("="*60)
    for row in fields_to_delete:
        has_map_str = " (COM MAPEAMENTO)" if row.get("OBJECT_MAPPING_ID") != "N√£o possui mapeamento" else ""
        print(f"- DMO: {row['DMO_DISPLAY_NAME']} | Campo: {row['FIELD_DISPLAY_NAME']}{has_map_str}")
    
    if dry_run:
        print("\nüê´ EXECUTANDO EM MODO DE SIMULA√á√ÉO (DRY RUN). NENHUM METADADO SER√Å ALTERADO.")
    else:
        print("\n" + "!"*60)
        print("Esta a√ß√£o √© IRREVERS√çVEL. Uma vez deletados, os metadados n√£o podem ser recuperados.")
        confirm = input("üëâ Para confirmar a exclus√£o, digite 'CONFIRMAR' e pressione Enter: ")
        if confirm != 'CONFIRMAR':
            print("\nüö´ Exclus√£o cancelada pelo usu√°rio.")
            return
        print("\n‚úÖ Confirma√ß√£o recebida. Iniciando processo de exclus√£o...")

    auth_data = get_access_token()
    access_token = auth_data['access_token']
    instance_url = auth_data['instance_url']
    headers = {'Authorization': f'Bearer {access_token}', 'Content-Type': 'application/json'}
    
    proxy_url = os.getenv("PROXY_URL")
    if proxy_url:
        print(f"üåç Usando proxy para chamadas de API: {proxy_url}")

    async with aiohttp.ClientSession(headers=headers, proxy=proxy_url) as session:
        tasks = []
        print("\nüîé Iniciando processamento dos campos para exclus√£o...")
        for row in fields_to_delete:
            tasks.append(process_single_field_deletion(session, instance_url, row, dry_run))

        if not tasks:
            print("\nNenhum campo p√¥de ser processado para exclus√£o.")
            return
        
        results = await asyncio.gather(*tasks)
    
        successful_deletions = []
        failed_deletions = []
        for field, success, reason in results:
            if success:
                successful_deletions.append(field)
            else:
                failed_deletions.append({'field': field, 'reason': reason})

        # Gera os arquivos CSV com os resultados, se houver e se n√£o for dry-run.
        if not dry_run:
            if successful_deletions:
                write_success_log_to_csv(successful_deletions)
            if failed_deletions:
                write_failure_log_to_csv(failed_deletions)

        print("\n" + "="*60)
        print("üìä RELAT√ìRIO FINAL DE EXCLUS√ÉO")
        print("="*60)

        # Lista de Sucessos
        print(f"\n‚úÖ Campos Deletados com Sucesso: {len(successful_deletions)}")
        if successful_deletions:
            for field_name in successful_deletions:
                print(f"  - {field_name}")
        
        # Lista de Falhas
        print(f"\n‚ùå Falhas na Dele√ß√£o: {len(failed_deletions)}")
        if failed_deletions:
            for failure in failed_deletions:
                print(f"  - Campo: {failure['field']}")
                print(f"    Motivo: {failure['reason']}")
        
        print("\n" + "="*60)

        if dry_run:
            print("üê´ Simula√ß√£o (Dry Run) conclu√≠da. Nenhum dado foi alterado.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Deleta em massa campos de DMOs baseados em um arquivo CSV.")
    parser.add_argument(
        '--file', 
        default='audit_campos_dmo_nao_utilizados.csv', 
        help="Caminho para o arquivo CSV de auditoria (padr√£o: 'audit_campos_dmo_nao_utilizados.csv')"
    )
    parser.add_argument(
        '--dry-run', 
        action='store_true', 
        help="Executa o script em modo de simula√ß√£o, sem deletar nenhum metadado."
    )
    args = parser.parse_args()

    start_time = time.time()
    try:
        asyncio.run(mass_delete_fields(args.file, args.dry_run))
    except Exception as e:
        print(f"\n‚ùå Ocorreu um erro inesperado e fatal durante a execu√ß√£o: {e}")
    finally:
        end_time = time.time()
        duration = end_time - start_time
        print(f"\nTempo total de execu√ß√£o: {duration:.2f} segundos")